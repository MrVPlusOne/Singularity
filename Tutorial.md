### Where to find all solved benchmarks


object BenchmarkDriver in `cli.BenchmarkDriver`


<img src="tutorial/Driver.png" alt="Driver.png" width="700">


In order to define a new fuzzing task (referred to as "problem configuration" in our paper), we need a `FuzzingTaskProvider`, which is a trait (similar to an abstract class in Java) that defines the following methods. Only `task` and `sizeF` are required to be implemented, the other methods can be overwritten as needed.
```scala
trait FuzzingTaskProvider{
  protected def task: RunningFuzzingTask

  def sizeF: PartialFunction[IS[EValue], Int]

  def setupTask(task: RunningFuzzingTask): Unit = {}

  def teardownTask(task: RunningFuzzingTask): Unit = {}

  def displayValue: PartialFunction[IS[EValue], String] = {
    case v => v.toString
  }

  def saveValueWithName(value: IS[EValue], name: String): Unit = {
    ...
  }

  def run[A](f: RunningFuzzingTask => A): A = {
    ...
  }
}
```
### The quickSort example
where: `FuzzingTaskProvider.quickSortExample`

```scala
def quickSortExample = new FuzzingTaskProvider {
    import patbench.slowfuzz.QuickSort

    protected def task: RunningFuzzingTask = RunningFuzzingTask(
      outputTypes = IS(EVect(EInt)),
      resourceUsage = {
        case IS(VectValue(vec)) =>
          Cost.reset()
          val args = toIntVect(vec).map(i=>i.toString).toArray
          QuickSort.main(args)
          Cost.read()
      },
      gpEnv = sortingEnv
    )

    def sizeF = {
      case IS(VectValue(v)) =>
        v.length
    }
  }
```
function `quickSortExample` (we use `def` keyword to define functions in scala) defines how to create a new `FuzzingTaskProvider` anonymous class by implementing `task` and `sizeF` in the class body.
`sizeF` specifies the size metric to measure how big a task input is. Since the program of interest can accept multiple arguments in general, sizeF takes an input of type `IS[EValue]`.

`IS[T]` is just a convenient synonym for `IndexedSeq[T]` that is used through out this project.

Here since our task input is just a vector of integer, we use a pattern match in `sizeF`'s body to match an input of type `IS[EValue]` against pattern `IS(VectValue(v))`, then we use `v`'s length as size.


VectValue's definition:
```scala
case class VectValue(value: Vector[EValue]) extends EValue
```

Note that `Vector` is Scala's immutable indexed sequence data structure, while `VectValue` is an `EValue` which is defined in this project. The naming convention is that anything whose name followed by a "Value" is an `EValue`.

We also need to implement `task` to specify how to create a `RunningFuzzingTask`, in which we specify `outputTypes` and `resourceUsage`. Here `outputTypes` is the input types of the program of interest, it is called "outputTypes" in the sense that it is also the value type of the infinite patterns generated by our DSL programs (recurrent computation graphs).

`gpEnv` requires more explanation: it specifies the DSL we are using for this task. We have defined `sortingEnv` for multiple sorting examples.

```scala
def sortingEnv: GPEnvironment = {
    val constMap = makeConstMap(
      EInt -> IS(r => r.nextInt(12)),
      EVect(EInt) -> IS(_ => Vector())
    )

    val functions = IntComponents.collection ++ VectComponents.collection

    val stateTypes = constMap.keys.toIndexedSeq
    GPEnvironment(constMap, functions, stateTypes)
  }
```

`constMap` specifies how to create random constants of different types; these constants correspond to leaf noeds in the generated ASTs. `functions` specifies which functions (i.e. components) the GP algorithm uses as internal nodes to create ASTs.

Finally, `stateTypes` is an `IndexedSeq[EType]` that specifies how many internal states one recurrent computation graph should use and their corresponding types. In this example, we choose the keys of `constMap` as stateTypes, so it's just `IS(EInt, EVect(EInt))`.

Now we can run this example using `Runner.runExample` whose signature is
```scala
def runExample(taskProvider: FuzzingTaskProvider, seeds: Seq[Int], config: RunConfig = RunConfig.default,
                 useGUI: Boolean = true)
```
 the following code
```scala
runExample(FuzzingTaskProvider.quickSortExample, Seq(ioId))
```

`runExample` takes a `RunConfig` and uses it to adjust our GP algorithm's parameters.

The default parameters are shown below:

```scala
case class RunConfig(populationSize: Int = 500,
                       tournamentSize: Int = 7,
                       evaluationTrials: Int = 1,
                       totalSizeTolerance: Int = 60,
                       singleSizeTolerance: Int = 30,
                       threadNum: Int = 1,
                       timeLimitInMillis: Int = 20000,
                       maxNonIncreaseTime: Int = 150
                      ){
```
Some parameters that require extra explanations:

- `evaluationTrials`: The "window size" used for pattern evaluation. The last `evaluationTrials` ones are used to evaluate the performance of a pattern by taking their max.

- `totalSizeTolerance`: In our GP algorithm, fitness is calculated by multiplying the actual performance with a size penalty factor, so larger programs (with more AST nodes) would get more penalty. This parameters determines the penalty strength, once the total AST size gets closer to this value, the fitness drops rapidly.

- `singleSizeTolerance`: similar to `totalSizeTolerance` except that it determines how to penalize the individual AST for each internal state.

- `timeLimitInMillis`: The GP process is terminated once an input's evaluation exceeds this time. The timed out individual is automatically saved into log directories ($projectRoot/results/*).

- `maxNonIncreaseTime`: The GP process is also terminated once there hasn't been seen any performance increase after this number of generations.


### How to extend the DSL: Introduce pairs

Let's see how pairs are introduced as a new data type in our DSL.

(The code snippets in this example are taken from [StandardSystem.scala](src/main/scala/patsyn/StandardSystem.scala))

First, we introduce `EPair` as the type of generic pairs.
```scala
case class EPair(t1: EType, t2: EType) extends EType
```


Then, we also need a data structure to represent the values of pairs in our DSL. Here we just define `PairValue` as a wrapper of a (Scala) pair of `EValue`s.

```scala
case class PairValue(value: (EValue, EValue)) extends EValue{
    def hasType(ty: EType): Boolean = ty match {
      case EPair(t1, t2) => value._1.hasType(t1) && value._2.hasType(t2)
      case _ => false
    }

    def size: Long = value._1.size + value._2.size
  }
```

Note that extending `EValue` requires us to implement `hasType` and `size`.
`hasType` is used for performing polymorphic type checking. And `size` here is some task-independent size metric and it should be a **positive** `Long`. For example, for `VectorValue(v)`, we choose `v.length+1` as this size instead of just `v.length`. (this size metric is used to limit our generated program's memory consumption; without this limit, a recurrent computation graph can easily use out all of our machines' memory during pattern generation)

Next (this step is entirely optional), we use Scala's implicits feature to define a implicit conversion from a Scala pair to `PairValue`. In the future, wherever we need `PairValue`, we can just use a Scala pair instead. We also have implicit conversions for other `EValue`s types.
```scala
implicit def pairValue[A,B](p: (A, B))(implicit convA: A => EValue, convB: B => EValue): PairValue = {
    (PairValue(convA(p._1), convB(p._2)))
  }
```

Finally, we define some pair-related components for pair creation and accessing.
```scala
object PairComponents {
    val pair1 = EAbstractFunc("pair1", tyVarNum = 2,
      typeInstantiation = {
        case IS(t1,t2) => IS(EPair(t1,t2)) -> t1
      }, eval = {
        case IS(PairValue(value)) => value._1
      }
    )

    val pair2 = EAbstractFunc("pair2", tyVarNum = 2,
      typeInstantiation = {
        case IS(t1,t2) => IS(EPair(t1,t2)) -> t2
      }, eval = {
        case IS(PairValue(value)) => value._2
      }
    )

    val mkPair = EAbstractFunc("mkPair", tyVarNum = 2,
      typeInstantiation = {
        case IS(t1,t2) => IS(t1,t2) -> EPair(t1,t2)
      }, eval = {
        case IS(v1,v2) => (v1,v2)
      }
    )

    val collection: IndexedSeq[EFunction] = IS(pair1, pair2, mkPair)

    // examples on how to make a concrete version
    val mkIntPair: EConcreteFunc = mkPair.concretize(IS(EInt, EInt))
  }
```
Note that because those three components are all generic functions, we use `EAbstractfunc` and provide each of them a name, a type variable number, a type instantiation rule for calculating the type signature from type arguments, and finally an evaluation rule.

As the last line in the above code snippet demonstrates, an abstract function can be instantiated into an `EConcreteFunc` by calling the concretize method.

Actually, our GP only works on concrete components, and all abstract components are automatically concretized before GP starts. So you can use both `EConcreteFunc`s and `EAbstractFunc`s to construct `GPEnvironment`s.


### Further reading
You can see more examples in [ExampleAlgorithms.scala](src/main/scala/patsyn/ExampleAlgorithms.scala).